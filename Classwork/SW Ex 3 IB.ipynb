{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ready-expense",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "capable-footwear",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train row 0 (50000, 32, 32, 3) [[[ 59  62  63]\n",
      "  [ 43  46  45]\n",
      "  [ 50  48  43]\n",
      "  ...\n",
      "  [158 132 108]\n",
      "  [152 125 102]\n",
      "  [148 124 103]]\n",
      "\n",
      " [[ 16  20  20]\n",
      "  [  0   0   0]\n",
      "  [ 18   8   0]\n",
      "  ...\n",
      "  [123  88  55]\n",
      "  [119  83  50]\n",
      "  [122  87  57]]\n",
      "\n",
      " [[ 25  24  21]\n",
      "  [ 16   7   0]\n",
      "  [ 49  27   8]\n",
      "  ...\n",
      "  [118  84  50]\n",
      "  [120  84  50]\n",
      "  [109  73  42]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[208 170  96]\n",
      "  [201 153  34]\n",
      "  [198 161  26]\n",
      "  ...\n",
      "  [160 133  70]\n",
      "  [ 56  31   7]\n",
      "  [ 53  34  20]]\n",
      "\n",
      " [[180 139  96]\n",
      "  [173 123  42]\n",
      "  [186 144  30]\n",
      "  ...\n",
      "  [184 148  94]\n",
      "  [ 97  62  34]\n",
      "  [ 83  53  34]]\n",
      "\n",
      " [[177 144 116]\n",
      "  [168 129  94]\n",
      "  [179 142  87]\n",
      "  ...\n",
      "  [216 184 140]\n",
      "  [151 118  84]\n",
      "  [123  92  72]]]\n",
      "y_train row 0 [6]\n",
      "3072\n",
      "[0.23137255 0.24313726 0.24705882 ... 0.48235294 0.36078432 0.28235295]\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "print (\"x_train row 0\",x_train.shape,x_train[0])\n",
    "print (\"y_train row 0\",y_train[0])\n",
    "num_pixels = x_train.shape[1] * x_train.shape[2]*x_train.shape[3]\n",
    "x_train = x_train.reshape(x_train.shape[0], num_pixels).astype('float32')\n",
    "x_test = x_test.reshape(x_test.shape[0], num_pixels).astype('float32')\n",
    "x_train=x_train/255\n",
    "x_test=x_test/255\n",
    "print(num_pixels)\n",
    "print (x_train[0])\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "num_classes = y_test.shape[1]\n",
    "print(num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "racial-stereo",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_model():\n",
    "  model = Sequential()\n",
    "  model.add(tf.keras.Input(shape=(num_pixels,)))\n",
    "  model.add(Dense(300, activation='relu'))\n",
    "  model.add(Dense(50, activation='relu'))\n",
    "  model.add(Dense(10, activation='softmax'))\n",
    "  model.compile(optimizer='SGD', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "related-information",
   "metadata": {},
   "source": [
    "The prior cell creates a sequential model with 937,460 trainable parameters. ((3072+1)*300) + (300*50) +(50*10) +10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "mysterious-metro",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_31 (Dense)            (None, 300)               921900    \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 50)                15050     \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 10)                510       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 937,460\n",
      "Trainable params: 937,460\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "782/782 - 4s - loss: 1.9329 - accuracy: 0.3039 - val_loss: 1.8446 - val_accuracy: 0.3414 - 4s/epoch - 5ms/step\n",
      "Epoch 2/20\n",
      "782/782 - 3s - loss: 1.7567 - accuracy: 0.3774 - val_loss: 1.7967 - val_accuracy: 0.3586 - 3s/epoch - 4ms/step\n",
      "Epoch 3/20\n",
      "782/782 - 4s - loss: 1.6793 - accuracy: 0.4050 - val_loss: 1.7306 - val_accuracy: 0.3765 - 4s/epoch - 5ms/step\n",
      "Epoch 4/20\n",
      "782/782 - 4s - loss: 1.6258 - accuracy: 0.4266 - val_loss: 1.6323 - val_accuracy: 0.4267 - 4s/epoch - 5ms/step\n",
      "Epoch 5/20\n",
      "782/782 - 4s - loss: 1.5836 - accuracy: 0.4403 - val_loss: 1.6282 - val_accuracy: 0.4223 - 4s/epoch - 5ms/step\n",
      "Epoch 6/20\n",
      "782/782 - 3s - loss: 1.5466 - accuracy: 0.4540 - val_loss: 1.5949 - val_accuracy: 0.4418 - 3s/epoch - 4ms/step\n",
      "Epoch 7/20\n",
      "782/782 - 4s - loss: 1.5189 - accuracy: 0.4657 - val_loss: 1.5959 - val_accuracy: 0.4334 - 4s/epoch - 5ms/step\n",
      "Epoch 8/20\n",
      "782/782 - 3s - loss: 1.4904 - accuracy: 0.4745 - val_loss: 1.5353 - val_accuracy: 0.4497 - 3s/epoch - 4ms/step\n",
      "Epoch 9/20\n",
      "782/782 - 4s - loss: 1.4658 - accuracy: 0.4816 - val_loss: 1.6506 - val_accuracy: 0.4138 - 4s/epoch - 5ms/step\n",
      "Epoch 10/20\n",
      "782/782 - 4s - loss: 1.4450 - accuracy: 0.4905 - val_loss: 1.5888 - val_accuracy: 0.4392 - 4s/epoch - 5ms/step\n",
      "Epoch 11/20\n",
      "782/782 - 4s - loss: 1.4230 - accuracy: 0.4956 - val_loss: 1.5199 - val_accuracy: 0.4699 - 4s/epoch - 5ms/step\n",
      "Epoch 12/20\n",
      "782/782 - 4s - loss: 1.4015 - accuracy: 0.5047 - val_loss: 1.5152 - val_accuracy: 0.4616 - 4s/epoch - 5ms/step\n",
      "Epoch 13/20\n",
      "782/782 - 4s - loss: 1.3849 - accuracy: 0.5095 - val_loss: 1.5337 - val_accuracy: 0.4580 - 4s/epoch - 5ms/step\n",
      "Epoch 14/20\n",
      "782/782 - 4s - loss: 1.3687 - accuracy: 0.5169 - val_loss: 1.4913 - val_accuracy: 0.4770 - 4s/epoch - 5ms/step\n",
      "Epoch 15/20\n",
      "782/782 - 4s - loss: 1.3524 - accuracy: 0.5227 - val_loss: 1.6140 - val_accuracy: 0.4378 - 4s/epoch - 5ms/step\n",
      "Epoch 16/20\n",
      "782/782 - 4s - loss: 1.3399 - accuracy: 0.5289 - val_loss: 1.4554 - val_accuracy: 0.4848 - 4s/epoch - 5ms/step\n",
      "Epoch 17/20\n",
      "782/782 - 3s - loss: 1.3235 - accuracy: 0.5318 - val_loss: 1.4336 - val_accuracy: 0.4883 - 3s/epoch - 4ms/step\n",
      "Epoch 18/20\n",
      "782/782 - 4s - loss: 1.3110 - accuracy: 0.5364 - val_loss: 1.5103 - val_accuracy: 0.4745 - 4s/epoch - 5ms/step\n",
      "Epoch 19/20\n",
      "782/782 - 4s - loss: 1.2982 - accuracy: 0.5397 - val_loss: 1.4269 - val_accuracy: 0.4942 - 4s/epoch - 5ms/step\n",
      "Epoch 20/20\n",
      "782/782 - 4s - loss: 1.2861 - accuracy: 0.5455 - val_loss: 1.3788 - val_accuracy: 0.5091 - 4s/epoch - 5ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f84f36ebe50>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = classification_model()\n",
    "model1.summary()\n",
    "model1.fit(x_train, y_train, validation_data=(x_test, y_test),batch_size=64, epochs=20, verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "needed-scanning",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.5091000199317932 \n",
      " Error: 0.4908999800682068\n"
     ]
    }
   ],
   "source": [
    "scores = model1.evaluate(x_test, y_test, verbose=0)\n",
    "print('Model Accuracy: {} \\n Error: {}'.format(scores[1], 1 - scores[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "successful-german",
   "metadata": {},
   "source": [
    "The training set reached an accuracy of 54.55%.  The validation accuracy was a little lower at 50.9%.  I tried using more or less neurons in the hidden layers and that did not see to have a great effect on the numbers. Over multiple trials with different number of neurons, The best validation accuracy I could get was a little under 54% (40 epochs) and the worst was around 46.5%. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "north-throw",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_34 (Dense)            (None, 300)               921900    \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 50)                15050     \n",
      "                                                                 \n",
      " dense_36 (Dense)            (None, 10)                510       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 937,460\n",
      "Trainable params: 937,460\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "782/782 - 4s - loss: 1.9259 - accuracy: 0.3095 - val_loss: 1.8541 - val_accuracy: 0.3227 - 4s/epoch - 5ms/step\n",
      "Epoch 2/40\n",
      "782/782 - 4s - loss: 1.7561 - accuracy: 0.3787 - val_loss: 1.7412 - val_accuracy: 0.3748 - 4s/epoch - 5ms/step\n",
      "Epoch 3/40\n",
      "782/782 - 4s - loss: 1.6771 - accuracy: 0.4065 - val_loss: 1.7523 - val_accuracy: 0.3742 - 4s/epoch - 5ms/step\n",
      "Epoch 4/40\n",
      "782/782 - 4s - loss: 1.6263 - accuracy: 0.4243 - val_loss: 1.6039 - val_accuracy: 0.4288 - 4s/epoch - 5ms/step\n",
      "Epoch 5/40\n",
      "782/782 - 3s - loss: 1.5849 - accuracy: 0.4401 - val_loss: 1.7005 - val_accuracy: 0.4029 - 3s/epoch - 4ms/step\n",
      "Epoch 6/40\n",
      "782/782 - 3s - loss: 1.5473 - accuracy: 0.4547 - val_loss: 1.5430 - val_accuracy: 0.4547 - 3s/epoch - 4ms/step\n",
      "Epoch 7/40\n",
      "782/782 - 4s - loss: 1.5187 - accuracy: 0.4626 - val_loss: 1.6879 - val_accuracy: 0.4104 - 4s/epoch - 4ms/step\n",
      "Epoch 8/40\n",
      "782/782 - 5s - loss: 1.4901 - accuracy: 0.4743 - val_loss: 1.6258 - val_accuracy: 0.4153 - 5s/epoch - 6ms/step\n",
      "Epoch 9/40\n",
      "782/782 - 4s - loss: 1.4673 - accuracy: 0.4818 - val_loss: 1.6266 - val_accuracy: 0.4060 - 4s/epoch - 6ms/step\n",
      "Epoch 10/40\n",
      "782/782 - 3s - loss: 1.4464 - accuracy: 0.4902 - val_loss: 1.5557 - val_accuracy: 0.4407 - 3s/epoch - 4ms/step\n",
      "Epoch 11/40\n",
      "782/782 - 4s - loss: 1.4239 - accuracy: 0.4975 - val_loss: 1.5917 - val_accuracy: 0.4290 - 4s/epoch - 5ms/step\n",
      "Epoch 12/40\n",
      "782/782 - 4s - loss: 1.4090 - accuracy: 0.5017 - val_loss: 1.4770 - val_accuracy: 0.4716 - 4s/epoch - 5ms/step\n",
      "Epoch 13/40\n",
      "782/782 - 4s - loss: 1.3881 - accuracy: 0.5103 - val_loss: 1.5075 - val_accuracy: 0.4513 - 4s/epoch - 5ms/step\n",
      "Epoch 14/40\n",
      "782/782 - 4s - loss: 1.3714 - accuracy: 0.5139 - val_loss: 1.6043 - val_accuracy: 0.4199 - 4s/epoch - 5ms/step\n",
      "Epoch 15/40\n",
      "782/782 - 3s - loss: 1.3532 - accuracy: 0.5221 - val_loss: 1.4500 - val_accuracy: 0.4746 - 3s/epoch - 4ms/step\n",
      "Epoch 16/40\n",
      "782/782 - 4s - loss: 1.3404 - accuracy: 0.5267 - val_loss: 1.4470 - val_accuracy: 0.4866 - 4s/epoch - 5ms/step\n",
      "Epoch 17/40\n",
      "782/782 - 4s - loss: 1.3239 - accuracy: 0.5313 - val_loss: 1.4014 - val_accuracy: 0.5001 - 4s/epoch - 5ms/step\n",
      "Epoch 18/40\n",
      "782/782 - 4s - loss: 1.3115 - accuracy: 0.5360 - val_loss: 1.5005 - val_accuracy: 0.4602 - 4s/epoch - 5ms/step\n",
      "Epoch 19/40\n",
      "782/782 - 4s - loss: 1.3002 - accuracy: 0.5388 - val_loss: 1.4242 - val_accuracy: 0.4939 - 4s/epoch - 5ms/step\n",
      "Epoch 20/40\n",
      "782/782 - 4s - loss: 1.2841 - accuracy: 0.5478 - val_loss: 1.4951 - val_accuracy: 0.4582 - 4s/epoch - 5ms/step\n",
      "Epoch 21/40\n",
      "782/782 - 3s - loss: 1.2743 - accuracy: 0.5501 - val_loss: 1.5088 - val_accuracy: 0.4509 - 3s/epoch - 4ms/step\n",
      "Epoch 22/40\n",
      "782/782 - 4s - loss: 1.2600 - accuracy: 0.5550 - val_loss: 1.5111 - val_accuracy: 0.4719 - 4s/epoch - 5ms/step\n",
      "Epoch 23/40\n",
      "782/782 - 4s - loss: 1.2513 - accuracy: 0.5577 - val_loss: 1.5234 - val_accuracy: 0.4687 - 4s/epoch - 5ms/step\n",
      "Epoch 24/40\n",
      "782/782 - 3s - loss: 1.2401 - accuracy: 0.5625 - val_loss: 1.4806 - val_accuracy: 0.4663 - 3s/epoch - 4ms/step\n",
      "Epoch 25/40\n",
      "782/782 - 3s - loss: 1.2283 - accuracy: 0.5664 - val_loss: 1.4939 - val_accuracy: 0.4718 - 3s/epoch - 4ms/step\n",
      "Epoch 26/40\n",
      "782/782 - 3s - loss: 1.2186 - accuracy: 0.5701 - val_loss: 1.8576 - val_accuracy: 0.3896 - 3s/epoch - 4ms/step\n",
      "Epoch 27/40\n",
      "782/782 - 4s - loss: 1.2073 - accuracy: 0.5737 - val_loss: 1.4299 - val_accuracy: 0.4954 - 4s/epoch - 5ms/step\n",
      "Epoch 28/40\n",
      "782/782 - 4s - loss: 1.1953 - accuracy: 0.5787 - val_loss: 1.4105 - val_accuracy: 0.4986 - 4s/epoch - 5ms/step\n",
      "Epoch 29/40\n",
      "782/782 - 3s - loss: 1.1887 - accuracy: 0.5828 - val_loss: 1.3807 - val_accuracy: 0.5030 - 3s/epoch - 4ms/step\n",
      "Epoch 30/40\n",
      "782/782 - 3s - loss: 1.1770 - accuracy: 0.5864 - val_loss: 1.4423 - val_accuracy: 0.5038 - 3s/epoch - 4ms/step\n",
      "Epoch 31/40\n",
      "782/782 - 4s - loss: 1.1624 - accuracy: 0.5905 - val_loss: 1.4677 - val_accuracy: 0.4836 - 4s/epoch - 4ms/step\n",
      "Epoch 32/40\n",
      "782/782 - 4s - loss: 1.1591 - accuracy: 0.5922 - val_loss: 1.4092 - val_accuracy: 0.4972 - 4s/epoch - 4ms/step\n",
      "Epoch 33/40\n",
      "782/782 - 3s - loss: 1.1452 - accuracy: 0.5976 - val_loss: 1.3777 - val_accuracy: 0.5178 - 3s/epoch - 4ms/step\n",
      "Epoch 34/40\n",
      "782/782 - 3s - loss: 1.1376 - accuracy: 0.6000 - val_loss: 1.4620 - val_accuracy: 0.4911 - 3s/epoch - 4ms/step\n",
      "Epoch 35/40\n",
      "782/782 - 4s - loss: 1.1286 - accuracy: 0.6023 - val_loss: 1.4309 - val_accuracy: 0.5030 - 4s/epoch - 5ms/step\n",
      "Epoch 36/40\n",
      "782/782 - 4s - loss: 1.1202 - accuracy: 0.6071 - val_loss: 1.4727 - val_accuracy: 0.4776 - 4s/epoch - 5ms/step\n",
      "Epoch 37/40\n",
      "782/782 - 4s - loss: 1.1102 - accuracy: 0.6107 - val_loss: 1.3816 - val_accuracy: 0.5201 - 4s/epoch - 5ms/step\n",
      "Epoch 38/40\n",
      "782/782 - 4s - loss: 1.0976 - accuracy: 0.6141 - val_loss: 1.4788 - val_accuracy: 0.4994 - 4s/epoch - 5ms/step\n",
      "Epoch 39/40\n",
      "782/782 - 4s - loss: 1.0893 - accuracy: 0.6177 - val_loss: 1.3972 - val_accuracy: 0.5100 - 4s/epoch - 5ms/step\n",
      "Epoch 40/40\n",
      "782/782 - 4s - loss: 1.0870 - accuracy: 0.6180 - val_loss: 1.3559 - val_accuracy: 0.5274 - 4s/epoch - 5ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f84f2017410>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = classification_model()\n",
    "model2.summary()\n",
    "model2.fit(x_train, y_train, validation_data=(x_test, y_test),batch_size=64, epochs=40, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "registered-equation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.527400016784668 \n",
      " Error: 0.47259998321533203\n"
     ]
    }
   ],
   "source": [
    "scores = model2.evaluate(x_test, y_test, verbose=0)\n",
    "print('Model Accuracy: {} \\n Error: {}'.format(scores[1], 1 - scores[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "increasing-medium",
   "metadata": {},
   "source": [
    "For the 40 Epoch model, the accuracy on the training set did improve by 7.3%  but the validation set accuracy increased by only 1.8% which does not seem like a really great return on double the compute time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "reflected-suspect",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 20 Epoch Neural Net Thinks its a: Dog\n",
      "The 40 Epoch Neural Net Thinks its a: Dog\n",
      "The image is a: Dog\n"
     ]
    }
   ],
   "source": [
    "labels_map = {\n",
    "  0: 'Airplane',\n",
    "  1: 'Automobile',\n",
    "  2: 'Bird',\n",
    "  3: 'Cat',\n",
    "  4: 'Deer',\n",
    "  5: 'Dog',\n",
    "  6: 'Frog',\n",
    "  7: 'Horse',\n",
    "  8: 'Ship',\n",
    "  9: 'Truck',\n",
    "}\n",
    "Z=np.random.randint(10000)\n",
    "predicted_vector1 = model1(np.expand_dims(x_test[Z], axis=0))\n",
    "predicted_vector2 = model2(np.expand_dims(x_test[Z], axis=0))\n",
    "predicted_index = np.argmax(predicted_vector1)\n",
    "predicted_index2 = np.argmax(predicted_vector2)\n",
    "print (\"The 20 Epoch Neural Net Thinks its a:\",labels_map[predicted_index] )\n",
    "print (\"The 40 Epoch Neural Net Thinks its a:\",labels_map[predicted_index2])\n",
    "print (\"The image is a:\",labels_map[np.argmax(y_test[Z])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "headed-punishment",
   "metadata": {},
   "source": [
    "I spent a lot of time this weekend trying to tweak the models (number of neurons in each layer) to see if I could find some optimal number but I couldn't acheive better than 54% accuracy on the validation set. I was able to get the trainng accuracy up ove 70% a few times but the validation still was around 53.5%.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
